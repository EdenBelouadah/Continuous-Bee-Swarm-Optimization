\chapter*{Introduction générale}

Suite au développement des sciences et des technologies, les
besoins de l‘être humain ont progressé et les problèmes traités sont
devenus très complexes et de très grande taille. Ces conditions ont
poussé les chercheurs à rechercher des méthodes d‘optimisation pour
résoudre les problèmes complexes.

Il existe deux catégories de problèmes d'optimisation, les problèmes d'optimisation combinatoire (à
variables discrètes) comme ceux du voyageur de commerce, du cube rubique… etc,
et les problèmes d'optimisation continue (à variables continues) comme les fonctions d'optimisation globale.

Plusieurs méthodes de résolution ont vu le jour. Dans le cas de l'optimisation combinatoire, on trouve des méthodes exactes et des méthodes approchées. Dans le cas de l’optimisation
continue, on trouve des méthodes basées sur la programmation linéaire et
d'autres sur la programmation non-linéaire \cite{boussaid}. 

Nous nous intéressons ici à l'optimisation continue par programmation non-linéaire et plus précisément par les méta-heuristiques qui sont des méthodes globales.

Le but de notre projet est d'adapter la méta-heuristique Bee Swarm Optimization (BSO), qui a été initialement conçue pour les problèmes d'optimisation combinatoire, aux problèmes d'optimisation continue sans perdre l'ossature générale de l’approche initiale.

Le mémoire est construit de cinq chapitres. Dans le premier, nous présentons quelques notions importantes dans le domaine
d'intérêt de notre projet. Le deuxième est consacré à l'état de l'art de l'optimisation continue pour étudier l'avancement global des solutions proposées par les chercheurs dans ce domaine. Dans le troisième chapitre, nous présentons CBSO qui est notre propre version continue de BSO. Puis vient l'implémentation de notre proposition et nous finissons par une présentation de nos expérimentations sur des benchmarks publics, avec une analyse des résultats.